apiVersion: batch/v1
kind: Job
metadata:
  name: cyclegan-train-job
spec:
  template:
    spec:
      nodeSelector:
        topology.kubernetes.io/region: us-west
        nautilus.io/linstor: "true"
      containers:
        - name: cyclegan-trainer
          image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp
          env:
            - name: REPO_PATH
              value: /app/pytorch-CycleGAN-and-pix2pix
          command:
            - "bash"
            - "-c"
          args:
            - |
              set -e
              
              echo "Starting automated training job..."
              
              # Install decompression tools
              apt-get update && apt-get install -y pigz pv
              
              # Clone repository
              git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git ${REPO_PATH}
              cd ${REPO_PATH}
              
              # Install requirements
              pip install -r requirements.txt
              
              # Find and decompress the latest dataset
              LATEST_DATASET=$(ls -t /data/processed_data_*.tar.gz 2>/dev/null | head -1)
              if [ -z "$LATEST_DATASET" ]; then
                echo "No compressed datasets found - run data_pod.yml first"
                exit 1
              fi
              
              # Extract compressed data
              echo "Found dataset: $LATEST_DATASET"
              pv "$LATEST_DATASET" | pigz -d | tar -xf - -C ${REPO_PATH}/datasets/
              echo "Dataset extracted to ${REPO_PATH}/datasets/"
              
              # Create output directories on PVC for results
              mkdir -p /data/results /data/checkpoints
              
              # Train the model
              python train.py \
                --dataroot ${REPO_PATH}/datasets/horse2zebra \
                --name production_run \
                --model cycle_gan \
                --n_epochs 100 \
                --n_epochs_decay 100 \
                --save_epoch_freq 10 \
                --display_freq 400 \
                --print_freq 100 \
                --checkpoints_dir /data/checkpoints \
                --gpu_ids 0
              
              # Test the model
              python test.py \
                --dataroot ${REPO_PATH}/datasets/horse2zebra \
                --name production_run \
                --model cycle_gan \
                --checkpoints_dir /data/checkpoints \
                --results_dir /data/results
              
              echo "Training complete"
              
          volumeMounts:
            - name: git-repo
              mountPath: /app
            - name: data-volume
              mountPath: /data
            - name: dshm
              mountPath: /dev/shm
          resources:
            limits:
              memory: 24Gi
              cpu: "12"
              nvidia.com/gpu: "1"
            requests:
              memory: 20Gi
              cpu: "10"
              nvidia.com/gpu: "1"
      volumes:
        - name: git-repo
          emptyDir: {}
        - name: data-volume
          persistentVolumeClaim:
            claimName: cyclegan-data-pvc
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 8Gi
      restartPolicy: Never
  backoffLimit: 1